import './menuT.css';
import { useNavigate } from 'react-router-dom';
import { useEffect, useState, useRef } from 'react';
import eulji from '../icons/eulji.png';
import drinklogo from '../icons/beverage-emoji-style.svg';
import springai from '../utils/springai';
import orderStartAudio from '../audio/start.mp3';

function Onboarding({ voiceMode, setVoiceMode }) {
  const navigate = useNavigate();
  const [port, setPort] = useState(null); // âœ… device â†’ port
  const [isConnected, setIsConnected] = useState(false);
  const [voiceEnabled, setVoiceEnabled] = useState(false);

  const [_isSpeaking, setIsSpeaking] = useState(false);
  const isSpeakingRef = useRef(false);
  const voiceEnabledRef = useRef(false);
  const voiceModeRef = useRef(voiceMode);
  const portRef = useRef(null); // âœ… deviceRef â†’ portRef
  const audioPlayerRef = useRef(null);
  const readerRef = useRef(null); // âœ… ì¶”ê°€
  
  const [userDetected, setUserDetected] = useState(false);
  const userDetectedRef = useRef(false);

  const API_BASE_URL = 'https://54-116-8-71.nip.io';

  useEffect(() => {
    voiceModeRef.current = voiceMode;
    
    if (!voiceMode) {
      console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ìŒì„± ì¸ì‹ ì¤‘ì§€');
      stopVoiceRecording();
    }
  }, [voiceMode]);

  const handleOrderTypeClick = () => {
    navigate('/main');
  };

  const enableVoice = async () => {
    if (!voiceEnabledRef.current) {
      try {
        console.log('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹œì‘');
        
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ íšë“ ì„±ê³µ');
        stream.getTracks().forEach(track => track.stop());
        
        const utterance = new SpeechSynthesisUtterance('');
        window.speechSynthesis.speak(utterance);
        
        setVoiceEnabled(true);
        voiceEnabledRef.current = true;
        console.log('âœ… ìŒì„± ë° ë§ˆì´í¬ ê¶Œí•œ í™œì„±í™” ì™„ë£Œ');
        
        setTimeout(() => {
          enterFullscreen();
        }, 500);
        
      } catch (error) {
        console.error('âŒ ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜:', error);
        alert('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    }
  };

  const enterFullscreen = () => {
    try {
      const elem = document.documentElement;
      if (elem.requestFullscreen) {
        elem.requestFullscreen();
      } else if (elem.webkitRequestFullscreen) {
        elem.webkitRequestFullscreen();
      } else if (elem.msRequestFullscreen) {
        elem.msRequestFullscreen();
      }
      console.log('ğŸ“º ì „ì²´í™”ë©´ ì „í™˜ ì™„ë£Œ');
    } catch (error) {
      console.error('ì „ì²´í™”ë©´ ì „í™˜ ì˜¤ë¥˜:', error);
    }
  };

  const playWelcomeMessage = () => {
    console.log('=== playWelcomeMessage í˜¸ì¶œë¨ ===');
    
    if (userDetectedRef.current) {
      console.log('[playWelcomeMessage] ì´ë¯¸ ì‚¬ìš©ì ê°ì§€ë¨ - ì¤‘ë³µ ì‹¤í–‰ ì°¨ë‹¨');
      return;
    }
    
    if (isSpeakingRef.current) {
      console.log('[playWelcomeMessage] ìŒì„± ì¬ìƒ ì¤‘, ì¤‘ë³µ ì¬ìƒ ì°¨ë‹¨');
      return;
    }
    
    if (!voiceEnabledRef.current) {
      console.log('[playWelcomeMessage] ìŒì„± ê¶Œí•œ ë¯¸í™œì„±í™” - ì¬ìƒ ë¶ˆê°€');
      return;
    }

    setUserDetected(true);
    userDetectedRef.current = true;
    console.log('âœ… ì‚¬ìš©ì ìµœì´ˆ ê°ì§€ - ì¶”ê°€ ê°ì§€ ë¹„í™œì„±í™”');

    console.log('[playWelcomeMessage] ìŒì„± ì¬ìƒ ì‹œì‘');
    setIsSpeaking(true);
    isSpeakingRef.current = true;

    const audio = new Audio(orderStartAudio);
    audio.volume = 1.0;
    
    audio.onended = () => {
      console.log('[audio] "ì£¼ë¬¸ì‹œì‘" ìŒì„± ì¬ìƒ ì¢…ë£Œ');
      
      if (!voiceModeRef.current) {
        setIsSpeaking(false);
        isSpeakingRef.current = false;
        return;
      }
      
      sendPreRecordedVoiceToBackend();
    };
    
    audio.onerror = (e) => {
      console.error('[audio] ìŒì„± ì¬ìƒ ì˜¤ë¥˜:', e);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      
      if (voiceModeRef.current) {
        startMicRecording();
      }
    };

    audio.play().catch(err => {
      console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', err);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
    });
  };

  const sendPreRecordedVoiceToBackend = async () => {
    try {
      const response = await fetch(orderStartAudio);
      const audioBlob = await response.blob();
      
      let fileToSend = audioBlob;
      
      if (!audioBlob.type || !audioBlob.type.includes('audio')) {
        fileToSend = new Blob([audioBlob], { type: 'audio/mpeg' });
      }
      
      const file = new File([fileToSend], 'order-start.mp3', { 
        type: 'audio/mpeg',
        lastModified: Date.now()
      });

      const formData = new FormData();
      formData.append('question', file);

      const backendResponse = await fetch(`${API_BASE_URL}/api/ai/chat-voice`, {
        method: 'POST',
        body: formData,
      });

      if (!backendResponse.ok) {
        throw new Error(`ë°±ì—”ë“œ ì‘ë‹µ ì—ëŸ¬: ${backendResponse.status}`);
      }

      const audioPlayer = audioPlayerRef.current;
      
      audioPlayer.addEventListener('ended', () => {
        setIsSpeaking(false);
        isSpeakingRef.current = false;

        if (voiceModeRef.current) {
          startMicRecording();
        }
      }, { once: true });

      await springai.voice.playAudioFormStreamingData(backendResponse, audioPlayer);

    } catch (error) {
      console.error('âŒ ì´ˆê¸° ìŒì„± ì „ì†¡ ì˜¤ë¥˜:', error);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      
      if (voiceModeRef.current) {
        startMicRecording();
      }
    }
  };

  const startMicRecording = () => {
    if (!springai || !springai.voice) {
      console.error('âŒ springai.jsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }
    
    if (!voiceModeRef.current) {
      return;
    }
    
    console.log('ğŸ¤ ìŒì„± ì¸ì‹ ë§ˆì´í¬ ì‹œì‘');
    springai.voice.initMic(handleVoice);
    springai.voice.controlSpeakerAnimation('user-speaker', true);
  };

  const stopVoiceRecording = () => {
    if (springai && springai.voice) {
      if (springai.voice.mediaRecorder && springai.voice.mediaRecorder.state === 'recording') {
        springai.voice.mediaRecorder.stop();
      }
      if (springai.voice.recognition) {
        springai.voice.recognition.stop();
      }
      springai.voice.controlSpeakerAnimation('user-speaker', false);
      springai.voice.controlSpeakerAnimation('ai-speaker', false);
    }
    window.speechSynthesis.cancel();
  };

  const checkKeywordAndNavigate = (recognizedText) => {
    const keywords = ['í¬ì¥', 'í…Œì´í¬ì•„ì›ƒ', 'take out', 'ë§¤ì¥', 'ë¨¹ê³ ', 'dine in', 'ì—¬ê¸°ì„œ'];
    
    const foundKeyword = keywords.some(keyword => 
      recognizedText.toLowerCase().includes(keyword.toLowerCase())
    );
    
    if (foundKeyword) {
      console.log('âœ… í‚¤ì›Œë“œ ê°ì§€! Main í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.');
      stopVoiceRecording();
      setTimeout(() => {
        navigate('/main');
      }, 1000);
      return true;
    }
    
    return false;
  };

  const handleVoice = async (mp3Blob) => {
    springai.voice.controlSpeakerAnimation('user-speaker', false);

    if (!voiceModeRef.current) {
      return;
    }

    const recognizedText = springai.voice.lastRecognizedText || '';

    const shouldNavigate = checkKeywordAndNavigate(recognizedText);
    if (shouldNavigate) {
      return;
    }

    if (mp3Blob.size < 5000) {
      setTimeout(() => {
        if (voiceModeRef.current) {
          startMicRecording();
        }
      }, 1000);
      return;
    }

    setIsSpeaking(true);
    isSpeakingRef.current = true;

    try {
      const formData = new FormData();
      formData.append('question', mp3Blob, 'user-speech.mp3');

      const response = await fetch(`${API_BASE_URL}/api/ai/chat-voice`, {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`ë°±ì—”ë“œ ì‘ë‹µ ì—ëŸ¬: ${response.status}`);
      }
      
      springai.voice.controlSpeakerAnimation('ai-speaker', true);

      const audioPlayer = audioPlayerRef.current;
      
      audioPlayer.addEventListener('ended', () => {
        springai.voice.controlSpeakerAnimation('ai-speaker', false);
        setIsSpeaking(false);
        isSpeakingRef.current = false;

        if (voiceModeRef.current) {
          setTimeout(() => {
            startMicRecording();
          }, 1000);
        }
      }, { once: true });

      await springai.voice.playAudioFormStreamingData(response, audioPlayer);

    } catch (error) {
      console.error('âŒ ìŒì„± ì²˜ë¦¬ ì¤‘ ì—ëŸ¬:', error);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      springai.voice.controlSpeakerAnimation('ai-speaker', false);
    }
  };

  // âœ… Web Serial APIë¡œ ì•„ë‘ì´ë…¸ ì—°ê²°
  const connectArduino = async () => {
    try {
      if (!('serial' in navigator)) {
        alert('âŒ Web Serial APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.\nChrome ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
        return;
      }

      console.log('ğŸ”Œ Web Serial APIë¡œ ì•„ë‘ì´ë…¸ ì—°ê²° ì‹œë„...');
      
      // âœ… ëª¨ë“  ì¥ì¹˜ í‘œì‹œ
      const selectedPort = await navigator.serial.requestPort({ 
        filters: []
      });

      console.log('âœ… í¬íŠ¸ ì„ íƒë¨');
      
      // âœ… 9600 baudë¡œ ì—´ê¸°
      await selectedPort.open({ baudRate: 9600 });
      console.log('âœ… í¬íŠ¸ ì—´ë¦¼ (9600 baud)');

      setPort(selectedPort);
      portRef.current = selectedPort;
      setIsConnected(true);
      
      // ë°ì´í„° ì½ê¸° ì‹œì‘
      readArduinoData(selectedPort);
      
      console.log('âœ… ì•„ë‘ì´ë…¸ ì—°ê²° ì„±ê³µ!');

    } catch (error) {
      console.error('ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨:', error);
      
      if (error.name === 'NotFoundError') {
        alert('í¬íŠ¸ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      } else {
        alert('ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨: ' + error.message);
      }
    }
  };

  const disconnectArduino = async () => {
    try {
      if (readerRef.current) {
        await readerRef.current.cancel();
        readerRef.current = null;
      }
      
      if (portRef.current) {
        await portRef.current.close();
      }
      
      setPort(null);
      portRef.current = null;
      setIsConnected(false);
      
      console.log('âœ… ì•„ë‘ì´ë…¸ ì—°ê²° í•´ì œ ì™„ë£Œ');
    } catch (error) {
      console.error('ì•„ë‘ì´ë…¸ ì—°ê²° í•´ì œ ì‹¤íŒ¨:', error);
    }
  };

  // âœ… Web Serial APIë¡œ ë°ì´í„° ì½ê¸°
  const readArduinoData = async (selectedPort) => {
    try {
      console.log('ğŸ“¡ ì•„ë‘ì´ë…¸ ë°ì´í„° ìˆ˜ì‹  ì‹œì‘...');
      
      const textDecoder = new TextDecoderStream();
      selectedPort.readable.pipeTo(textDecoder.writable);
      const reader = textDecoder.readable.getReader();
      readerRef.current = reader;

      while (true) {
        const { value, done } = await reader.read();
        
        if (done) {
          reader.releaseLock();
          readerRef.current = null;
          break;
        }
        
        if (value) {
          const lines = value.split('\n').map(line => line.trim()).filter(line => line.length > 0);
          
          for (const data of lines) {
            console.log('ğŸ“¡ ìˆ˜ì‹  ë°ì´í„°:', data);
            
            if (data.includes('USER_DETECTED')) {
              console.log(`ğŸ‰ ì‚¬ìš©ì ê°ì§€ë¨!`);
              
              if (userDetectedRef.current) {
                continue;
              }
              
              if (!isSpeakingRef.current && voiceEnabledRef.current) {
                playWelcomeMessage();
              }
            }
          }
        }
      }
    } catch (error) {
      console.error('ğŸ“¡ ì‹œë¦¬ì–¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜:', error);
      setIsConnected(false);
    }
  };

  useEffect(() => {
    const autoConnect = async () => {
      try {
        if ('serial' in navigator) {
          const ports = await navigator.serial.getPorts();

          if (ports.length > 0) {
            const selectedPort = ports[0];
            await selectedPort.open({ baudRate: 9600 });
            setPort(selectedPort);
            portRef.current = selectedPort;
            setIsConnected(true);
            readArduinoData(selectedPort);
            console.log('âœ… ì•„ë‘ì´ë…¸ ìë™ ì¬ì—°ê²° ì„±ê³µ!');
          }
        }
      } catch (error) {
        console.log('ìë™ ì—°ê²° ì‹¤íŒ¨');
      }
    };

    autoConnect();

    return () => {
      stopVoiceRecording();
      if (readerRef.current) readerRef.current.cancel().catch(console.error);
      if (portRef.current) portRef.current.close().catch(console.error);
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  return (
    <div className="mmaaiinn">
      {!voiceEnabled && (
        <div style={{
          position: 'fixed',
          top: '50%',
          left: '50%',
          transform: 'translate(-50%, -50%)',
          zIndex: 9999,
          background: 'white',
          padding: '40px',
          borderRadius: '20px',
          boxShadow: '0 10px 50px rgba(0,0,0,0.3)',
          textAlign: 'center'
        }}>
          <h2 style={{marginBottom: '20px', fontSize: '28px'}}>ğŸ”Š ìŒì„± ì•ˆë‚´ ì‹œì‘</h2>
          <p style={{marginBottom: '30px', fontSize: '18px', color: '#666'}}>
            ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
          </p>
          <button 
            className="voice-activation-btn"
            onClick={enableVoice}
            style={{
              background: '#4CAF50',
              color: 'white',
              padding: '20px 40px',
              fontSize: '24px',
              border: 'none',
              borderRadius: '10px',
              cursor: 'pointer',
              boxShadow: '0 4px 10px rgba(0,0,0,0.2)'
            }}
          >
            ìŒì„± í™œì„±í™”
          </button>
        </div>
      )}

      <div className="arduino-status">
        {isConnected ? (
          <div className="status-connected">
            <span className="status-dot"></span>
            ì•„ë‘ì´ë…¸ ì—°ê²°ë¨ (Web Serial)
            {userDetected && (
              <span style={{marginLeft: '10px', color: '#4CAF50', fontSize: '14px'}}>
                âœ“ ì‚¬ìš©ì ê°ì§€ë¨
              </span>
            )}
            {!voiceMode && (
              <span style={{marginLeft: '10px', color: '#FF9800', fontSize: '14px'}}>
                ğŸ–ï¸ í„°ì¹˜ ëª¨ë“œ
              </span>
            )}
            <button className="disconnect-btn arduino-btn" onClick={disconnectArduino} style={{marginLeft: '10px'}}>
              ğŸ”Œ ì—°ê²° í•´ì œ
            </button>
          </div>
        ) : (
          <button className="connect-btn arduino-btn" onClick={connectArduino}>
            ğŸ”Œ ì•„ë‘ì´ë…¸ ìˆ˜ë™ ì—°ê²°
          </button>
        )}
      </div>

      <audio ref={audioPlayerRef} style={{ display: 'none' }} />

      <div style={{ display: 'none' }}>
        <div id="user-speaker"></div>
        <div id="ai-speaker"></div>
      </div>

      <section className="onboard-total-ct">
        <div className="logo-ct">
          <div className="eulji-logo"> <img src={eulji} alt="eulji logo" /> </div>
          <div className="middle-line"><p> </p></div>
          <div className="kiosk-logo"> <img src={drinklogo} alt="drink logo" /> </div>
        </div>

        <div className="kiosk-title">EU AI ìŒì„± í‚¤ì˜¤ìŠ¤í¬ </div>
        <p className="kiosk-eng"> Ai Voice Kiosk </p>
        <p className="click"> í´ë¦­í•˜ì—¬ ì£¼ë¬¸í•˜ì„¸ìš”. </p>
        <p className="kiosk-solution"> ì£¼ë¬¸ ë°©ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”</p>

        <div className="order-method-ct">
          <section className="Take-out-ct" onClick={handleOrderTypeClick}>
            <div className="tt">
              <div className="takeout-img">ğŸ›ï¸</div>
            </div>
            <p className="takeout"> í¬ì¥ </p>
            <p className="takeout-sub"> Take out</p>
          </section>

          <section className="Dine-in-ct" onClick={handleOrderTypeClick}>
            <div className="tt2">
              <div className="dinein-img">ğŸª‘</div>
            </div>
            <p className="pack"> ë§¤ì¥ </p>
            <p className="pack-sub"> Dine in</p>
          </section>
        </div>
      </section>
    </div>
  );
}

export default Onboarding;
