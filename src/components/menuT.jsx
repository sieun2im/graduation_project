import './menuT.css';
import { useNavigate } from 'react-router-dom';
import { useEffect, useState, useRef } from 'react';
import eulji from '../icons/eulji.png';
import drinklogo from '../icons/beverage-emoji-style.svg';
import springai from '../utils/springai';
import orderStartAudio from '../audio/start.mp3';

function Onboarding({ voiceMode, setVoiceMode }) {
  const navigate = useNavigate();
  const [device, setDevice] = useState(null);
  const [isConnected, setIsConnected] = useState(false);
  const [voiceEnabled, setVoiceEnabled] = useState(false);

  const [_isSpeaking, setIsSpeaking] = useState(false);
  const isSpeakingRef = useRef(false);
  const voiceEnabledRef = useRef(false);
  const voiceModeRef = useRef(voiceMode);
  const deviceRef = useRef(null);
  const audioPlayerRef = useRef(null);
  const readingRef = useRef(false);
  
  const [userDetected, setUserDetected] = useState(false);
  const userDetectedRef = useRef(false);

  const API_BASE_URL = 'https://54-116-8-71.nip.io';

  useEffect(() => {
    voiceModeRef.current = voiceMode;
    
    if (!voiceMode) {
      console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ìŒì„± ì¸ì‹ ì¤‘ì§€');
      stopVoiceRecording();
    }
  }, [voiceMode]);

  const handleOrderTypeClick = () => {
    navigate('/main');
  };

  const enableVoice = async () => {
    if (!voiceEnabledRef.current) {
      try {
        console.log('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹œì‘');
        
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ íšë“ ì„±ê³µ');
        stream.getTracks().forEach(track => track.stop());
        
        const utterance = new SpeechSynthesisUtterance('');
        window.speechSynthesis.speak(utterance);
        
        setVoiceEnabled(true);
        voiceEnabledRef.current = true;
        console.log('âœ… ìŒì„± ë° ë§ˆì´í¬ ê¶Œí•œ í™œì„±í™” ì™„ë£Œ');
        
        setTimeout(() => {
          enterFullscreen();
        }, 500);
        
      } catch (error) {
        console.error('âŒ ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜:', error);
        
        if (error.name === 'NotAllowedError') {
          alert('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\në¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        } else if (error.name === 'NotFoundError') {
          alert('ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        } else {
          alert('ë§ˆì´í¬ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nHTTPS ì—°ê²°ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
        }
      }
    }
  };

  const enterFullscreen = () => {
    try {
      const elem = document.documentElement;
      if (elem.requestFullscreen) {
        elem.requestFullscreen();
      } else if (elem.webkitRequestFullscreen) {
        elem.webkitRequestFullscreen();
      } else if (elem.msRequestFullscreen) {
        elem.msRequestFullscreen();
      }
      console.log('ğŸ“º ì „ì²´í™”ë©´ ì „í™˜ ì™„ë£Œ');
    } catch (error) {
      console.error('ì „ì²´í™”ë©´ ì „í™˜ ì˜¤ë¥˜:', error);
    }
  };

  const playWelcomeMessage = () => {
    console.log('=== playWelcomeMessage í˜¸ì¶œë¨ ===');
    
    if (userDetectedRef.current) {
      console.log('[playWelcomeMessage] ì´ë¯¸ ì‚¬ìš©ì ê°ì§€ë¨ - ì¤‘ë³µ ì‹¤í–‰ ì°¨ë‹¨');
      return;
    }
    
    if (isSpeakingRef.current) {
      console.log('[playWelcomeMessage] ìŒì„± ì¬ìƒ ì¤‘, ì¤‘ë³µ ì¬ìƒ ì°¨ë‹¨');
      return;
    }
    
    if (!voiceEnabledRef.current) {
      console.log('[playWelcomeMessage] ìŒì„± ê¶Œí•œ ë¯¸í™œì„±í™” - ì¬ìƒ ë¶ˆê°€');
      return;
    }

    setUserDetected(true);
    userDetectedRef.current = true;
    console.log('âœ… ì‚¬ìš©ì ìµœì´ˆ ê°ì§€ - ì¶”ê°€ ê°ì§€ ë¹„í™œì„±í™”');

    console.log('[playWelcomeMessage] ìŒì„± ì¬ìƒ ì‹œì‘');
    setIsSpeaking(true);
    isSpeakingRef.current = true;

    const audio = new Audio(orderStartAudio);
    audio.volume = 1.0;
    
    audio.onplay = () => {
      console.log('ğŸ”Š "ì£¼ë¬¸ì‹œì‘" ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘');
    };
    
    audio.onended = () => {
      console.log('[audio] "ì£¼ë¬¸ì‹œì‘" ìŒì„± ì¬ìƒ ì¢…ë£Œ');
      
      if (!voiceModeRef.current) {
        console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™”ë¨ - ë°±ì—”ë“œ í˜¸ì¶œ ì¤‘ë‹¨');
        setIsSpeaking(false);
        isSpeakingRef.current = false;
        return;
      }
      
      sendPreRecordedVoiceToBackend();
    };
    
    audio.onerror = (e) => {
      console.error('[audio] ìŒì„± ì¬ìƒ ì˜¤ë¥˜:', e);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      
      if (voiceModeRef.current) {
        startMicRecording();
      }
    };

    audio.play().catch(err => {
      console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', err);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
    });
  };

  const sendPreRecordedVoiceToBackend = async () => {
    try {
      console.log('ğŸ“¤ ë…¹ìŒëœ "ì£¼ë¬¸ì‹œì‘" íŒŒì¼ì„ ë°±ì—”ë“œë¡œ ì „ì†¡ ì¤‘...');
      
      const response = await fetch(orderStartAudio);
      const audioBlob = await response.blob();
      
      let fileToSend = audioBlob;
      
      if (!audioBlob.type || audioBlob.type === '' || !audioBlob.type.includes('audio')) {
        console.warn('âš ï¸ íŒŒì¼ íƒ€ì…ì´ ì—†ê±°ë‚˜ ì˜ëª»ë¨, audio/mpegë¡œ ë³€í™˜');
        fileToSend = new Blob([audioBlob], { type: 'audio/mpeg' });
      }
      
      const file = new File([fileToSend], 'order-start.mp3', { 
        type: 'audio/mpeg',
        lastModified: Date.now()
      });

      const formData = new FormData();
      formData.append('question', file);

      console.log('ğŸ“¤ ë°±ì—”ë“œë¡œ ì „ì†¡ ì¤‘...');
      const backendResponse = await fetch(`${API_BASE_URL}/api/ai/chat-voice`, {
        method: 'POST',
        body: formData,
      });

      if (!backendResponse.ok) {
        const errorText = await backendResponse.text();
        console.error('ë°±ì—”ë“œ ì—ëŸ¬ ì‘ë‹µ:', errorText);
        throw new Error(`ë°±ì—”ë“œ ì‘ë‹µ ì—ëŸ¬: ${backendResponse.status}`);
      }

      console.log('âœ… ë°±ì—”ë“œ ì‘ë‹µ ìˆ˜ì‹ ');

      const audioPlayer = audioPlayerRef.current;
      
      audioPlayer.addEventListener('ended', () => {
        console.log('ğŸ”Š ë°±ì—”ë“œ AI ìŒì„± ì¬ìƒ ì™„ë£Œ');
        setIsSpeaking(false);
        isSpeakingRef.current = false;

        if (voiceModeRef.current) {
          startMicRecording();
        }
      }, { once: true });

      await springai.voice.playAudioFormStreamingData(backendResponse, audioPlayer);

    } catch (error) {
      console.error('âŒ ì´ˆê¸° ìŒì„± ì „ì†¡ ì˜¤ë¥˜:', error);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      
      if (voiceModeRef.current) {
        startMicRecording();
      }
    }
  };

  const startMicRecording = () => {
    if (!springai || !springai.voice) {
      console.error('âŒ springai.jsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }
    
    if (!voiceModeRef.current) {
      console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ë§ˆì´í¬ ì‹œì‘ ì¤‘ë‹¨');
      return;
    }
    
    console.log('ğŸ¤ ìŒì„± ì¸ì‹ ë§ˆì´í¬ ì‹œì‘');
    springai.voice.initMic(handleVoice);
    springai.voice.controlSpeakerAnimation('user-speaker', true);
  };

  const stopVoiceRecording = () => {
    if (springai && springai.voice) {
      if (springai.voice.mediaRecorder && springai.voice.mediaRecorder.state === 'recording') {
        springai.voice.mediaRecorder.stop();
      }
      if (springai.voice.recognition) {
        springai.voice.recognition.stop();
      }
      springai.voice.controlSpeakerAnimation('user-speaker', false);
      springai.voice.controlSpeakerAnimation('ai-speaker', false);
    }
    window.speechSynthesis.cancel();
  };

  const checkKeywordAndNavigate = (recognizedText) => {
    console.log('ğŸ” í‚¤ì›Œë“œ ì²´í¬:', recognizedText);
    
    const keywords = ['í¬ì¥', 'í…Œì´í¬ì•„ì›ƒ', 'take out', 'ë§¤ì¥', 'ë¨¹ê³ ', 'dine in', 'ì—¬ê¸°ì„œ'];
    
    const foundKeyword = keywords.some(keyword => 
      recognizedText.toLowerCase().includes(keyword.toLowerCase())
    );
    
    if (foundKeyword) {
      console.log('âœ… í‚¤ì›Œë“œ ê°ì§€! Main í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.');
      
      stopVoiceRecording();
      
      setTimeout(() => {
        navigate('/main');
      }, 1000);
      
      return true;
    }
    
    return false;
  };

  const handleVoice = async (mp3Blob) => {
    springai.voice.controlSpeakerAnimation('user-speaker', false);
    console.log('ğŸ¤ ì‚¬ìš©ì ìŒì„± ìˆ˜ì‹ :', mp3Blob);

    if (!voiceModeRef.current) {
      console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ìŒì„± ì²˜ë¦¬ ì¤‘ë‹¨');
      return;
    }

    const recognizedText = springai.voice.lastRecognizedText || '';
    console.log('ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:', recognizedText);

    const shouldNavigate = checkKeywordAndNavigate(recognizedText);
    if (shouldNavigate) {
      return;
    }

    if (mp3Blob.size < 5000) {
      console.warn('âš ï¸ ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.');
      setTimeout(() => {
        if (voiceModeRef.current) {
          startMicRecording();
        }
      }, 1000);
      return;
    }

    setIsSpeaking(true);
    isSpeakingRef.current = true;

    try {
      const formData = new FormData();
      formData.append('question', mp3Blob, 'user-speech.mp3');

      console.log('ğŸ“¤ ë°±ì—”ë“œë¡œ ìŒì„± ì „ì†¡ ì¤‘...');
      const response = await fetch(`${API_BASE_URL}/api/ai/chat-voice`, {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('ë°±ì—”ë“œ ì—ëŸ¬ ì‘ë‹µ:', errorText);
        throw new Error(`ë°±ì—”ë“œ ì‘ë‹µ ì—ëŸ¬: ${response.status}`);
      }

      console.log('âœ… ë°±ì—”ë“œ ì‘ë‹µ ìˆ˜ì‹ ');
      
      springai.voice.controlSpeakerAnimation('ai-speaker', true);

      const audioPlayer = audioPlayerRef.current;
      
      audioPlayer.addEventListener('ended', () => {
        console.log('ğŸ”Š AI ì‘ë‹µ ìŒì„± ì¬ìƒ ì™„ë£Œ');
        springai.voice.controlSpeakerAnimation('ai-speaker', false);
        setIsSpeaking(false);
        isSpeakingRef.current = false;

        if (voiceModeRef.current) {
          setTimeout(() => {
            startMicRecording();
          }, 1000);
        }
      }, { once: true });

      await springai.voice.playAudioFormStreamingData(response, audioPlayer);

    } catch (error) {
      console.error('âŒ ìŒì„± ì²˜ë¦¬ ì¤‘ ì—ëŸ¬:', error);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      springai.voice.controlSpeakerAnimation('ai-speaker', false);
      
      alert('ë°±ì—”ë“œ ì„œë²„ì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  };

  // âœ… WebUSBë¡œ ì•„ë‘ì´ë…¸ ì—°ê²°
  const connectArduino = async () => {
    try {
      if (!('usb' in navigator)) {
        alert('âŒ WebUSB APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.\nChrome ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
        return;
      }

      console.log('ğŸ”Œ WebUSBë¡œ ì•„ë‘ì´ë…¸ ì—°ê²° ì‹œë„...');
      
      // CH340 ì¹©ì…‹ í•„í„°
      const selectedDevice = await navigator.usb.requestDevice({ 
        filters: [
          { vendorId: 0x1a86 }, // CH340
          { vendorId: 0x0403 }, // FTDI
          { vendorId: 0x10c4 }, // CP210x
          { vendorId: 0x2341 }, // Arduino ì •í’ˆ
          { vendorId: 0x2a03 }  // Arduino ì •í’ˆ
        ]
      });

      console.log('âœ… USB ì¥ì¹˜ ì„ íƒë¨:', selectedDevice);
      
      // ì¥ì¹˜ ì—´ê¸°
      await selectedDevice.open();
      
      // Configuration ì„ íƒ (ëŒ€ë¶€ë¶„ 1ë²ˆ)
      if (selectedDevice.configuration === null) {
        await selectedDevice.selectConfiguration(1);
      }
      
      // Interface claim (CH340ì€ 0ë²ˆ)
      await selectedDevice.claimInterface(0);
      
      console.log('âœ… ì•„ë‘ì´ë…¸ WebUSB ì—°ê²° ì„±ê³µ!');
      
      setDevice(selectedDevice);
      deviceRef.current = selectedDevice;
      setIsConnected(true);
      
      // ë°ì´í„° ì½ê¸° ì‹œì‘
      readArduinoData(selectedDevice);

    } catch (error) {
      console.error('ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨:', error);
      
      if (error.name === 'NotFoundError') {
        alert('USB ì¥ì¹˜ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      } else if (error.name === 'SecurityError') {
        alert('USB ì ‘ê·¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\ní˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      } else {
        alert('ì•„ë‘ì´ë…¸ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n' + error.message);
      }
    }
  };

  const disconnectArduino = async () => {
    try {
      readingRef.current = false;
      
      if (deviceRef.current) {
        await deviceRef.current.close();
      }
      
      setDevice(null);
      deviceRef.current = null;
      setIsConnected(false);
      
      console.log('âœ… ì•„ë‘ì´ë…¸ ì—°ê²° í•´ì œ ì™„ë£Œ');
    } catch (error) {
      console.error('ì•„ë‘ì´ë…¸ ì—°ê²° í•´ì œ ì‹¤íŒ¨:', error);
    }
  };

  // âœ… WebUSBë¡œ ë°ì´í„° ì½ê¸°
  const readArduinoData = async (selectedDevice) => {
    readingRef.current = true;
    
    try {
      console.log('ğŸ“¡ ì•„ë‘ì´ë…¸ ë°ì´í„° ìˆ˜ì‹  ì‹œì‘...');
      
      // CH340ì€ endpoint 0x82 (IN), 64 bytes
      const endpointNumber = 2; // endpoint 0x82 = 2
      
      while (readingRef.current && deviceRef.current) {
        try {
          const result = await selectedDevice.transferIn(endpointNumber, 64);
          
          if (result.data && result.data.byteLength > 0) {
            const decoder = new TextDecoder();
            const text = decoder.decode(result.data);
            
            // ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬
            const lines = text.split('\n').map(line => line.trim()).filter(line => line.length > 0);
            
            for (const data of lines) {
              console.log('ğŸ“¡ ìˆ˜ì‹  ë°ì´í„°:', data);
              
              if (data.toUpperCase().includes('USER_DETECT')) {
                console.log(`[readArduinoData] USER_DETECTED ì‹ í˜¸ ìˆ˜ì‹ `);
                
                if (userDetectedRef.current) {
                  console.log('[readArduinoData] ì´ë¯¸ ì‚¬ìš©ì ê°ì§€ë¨ - ì¶”ê°€ ê°ì§€ ë¬´ì‹œ');
                  continue;
                }
                
                if (!isSpeakingRef.current && voiceEnabledRef.current) {
                  playWelcomeMessage();
                } else {
                  console.log('[readArduinoData] ìŒì„± ì¬ìƒ ì¤‘ì´ê±°ë‚˜ ìŒì„± ë¹„í™œì„±í™” ìƒíƒœ');
                }
              }
            }
          }
        } catch (readError) {
          if (readError.name === 'NetworkError') {
            console.log('ğŸ“¡ ì—°ê²° ëŠê¹€, ì¬ì—°ê²° ì‹œë„...');
            await new Promise(resolve => setTimeout(resolve, 1000));
          } else {
            throw readError;
          }
        }
      }
    } catch (error) {
      console.error('ğŸ“¡ ì‹œë¦¬ì–¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜:', error);
      setIsConnected(false);
      readingRef.current = false;
    }
  };

  useEffect(() => {
    const autoConnect = async () => {
      try {
        if ('usb' in navigator) {
          const devices = await navigator.usb.getDevices();

          if (devices.length > 0) {
            const selectedDevice = devices[0];
            
            await selectedDevice.open();
            if (selectedDevice.configuration === null) {
              await selectedDevice.selectConfiguration(1);
            }
            await selectedDevice.claimInterface(0);
            
            setDevice(selectedDevice);
            deviceRef.current = selectedDevice;
            setIsConnected(true);
            readArduinoData(selectedDevice);
            
            console.log('âœ… ì•„ë‘ì´ë…¸ ìë™ ì¬ì—°ê²° ì„±ê³µ!');
          }
        }
      } catch (error) {
        console.log('ìë™ ì—°ê²° ì‹¤íŒ¨:', error.message);
      }
    };

    autoConnect();

    return () => {
      stopVoiceRecording();
      readingRef.current = false;
      if (deviceRef.current) {
        deviceRef.current.close().catch(console.error);
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  return (
    <div className="mmaaiinn">
      {!voiceEnabled && (
        <div style={{
          position: 'fixed',
          top: '50%',
          left: '50%',
          transform: 'translate(-50%, -50%)',
          zIndex: 9999,
          background: 'white',
          padding: '40px',
          borderRadius: '20px',
          boxShadow: '0 10px 50px rgba(0,0,0,0.3)',
          textAlign: 'center'
        }}>
          <h2 style={{marginBottom: '20px', fontSize: '28px'}}>ğŸ”Š ìŒì„± ì•ˆë‚´ ì‹œì‘</h2>
          <p style={{marginBottom: '30px', fontSize: '18px', color: '#666'}}>
            ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
          </p>
          <button 
            className="voice-activation-btn"
            onClick={enableVoice}
            style={{
              background: '#4CAF50',
              color: 'white',
              padding: '20px 40px',
              fontSize: '24px',
              border: 'none',
              borderRadius: '10px',
              cursor: 'pointer',
              boxShadow: '0 4px 10px rgba(0,0,0,0.2)'
            }}
          >
            ìŒì„± í™œì„±í™”
          </button>
        </div>
      )}

      <div className="arduino-status">
        {isConnected ? (
          <div className="status-connected">
            <span className="status-dot"></span>
            ì•„ë‘ì´ë…¸ ì—°ê²°ë¨ (WebUSB)
            {userDetected && (
              <span style={{marginLeft: '10px', color: '#4CAF50', fontSize: '14px'}}>
                âœ“ ì‚¬ìš©ì ê°ì§€ë¨
              </span>
            )}
            {!voiceMode && (
              <span style={{marginLeft: '10px', color: '#FF9800', fontSize: '14px'}}>
                ğŸ–ï¸ í„°ì¹˜ ëª¨ë“œ
              </span>
            )}
            <button className="disconnect-btn arduino-btn" onClick={disconnectArduino} style={{marginLeft: '10px'}}>
              ğŸ”Œ ì—°ê²° í•´ì œ
            </button>
          </div>
        ) : (
          <button className="connect-btn arduino-btn" onClick={connectArduino}>
            ğŸ”Œ ì•„ë‘ì´ë…¸ ìˆ˜ë™ ì—°ê²° (WebUSB)
          </button>
        )}
      </div>

      <audio ref={audioPlayerRef} style={{ display: 'none' }} />

      <div style={{ display: 'none' }}>
        <div id="user-speaker"></div>
        <div id="ai-speaker"></div>
      </div>

      <section className="onboard-total-ct">
        <div className="logo-ct">
          <div className="eulji-logo"> <img src={eulji} alt="eulji logo" /> </div>
          <div className="middle-line"><p> </p></div>
          <div className="kiosk-logo"> <img src={drinklogo} alt="drink logo" /> </div>
        </div>

        <div className="kiosk-title">EU AI ìŒì„± í‚¤ì˜¤ìŠ¤í¬ </div>
        <p className="kiosk-eng"> Ai Voice Kiosk </p>
        <p className="click"> í´ë¦­í•˜ì—¬ ì£¼ë¬¸í•˜ì„¸ìš”. </p>
        <p className="kiosk-solution"> ì£¼ë¬¸ ë°©ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”</p>

        <div className="order-method-ct">
          <section className="Take-out-ct" onClick={handleOrderTypeClick}>
            <div className="tt">
              <div className="takeout-img">ğŸ›ï¸</div>
            </div>
            <p className="takeout"> í¬ì¥ </p>
            <p className="takeout-sub"> Take out</p>
          </section>

          <section className="Dine-in-ct" onClick={handleOrderTypeClick}>
            <div className="tt2">
              <div className="dinein-img">ğŸª‘</div>
            </div>
            <p className="pack"> ë§¤ì¥ </p>
            <p className="pack-sub"> Dine in</p>
          </section>
        </div>
      </section>
    </div>
  );
}

export default Onboarding;
