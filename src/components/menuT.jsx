import './menuT.css';
import { useNavigate } from 'react-router-dom';
import { useEffect, useState, useRef } from 'react';
import eulji from '../icons/eulji.png';
import drinklogo from '../icons/beverage-emoji-style.svg';
import springai from '../utils/springai';
import orderStartAudio from '../audio/start.mp3';

function Onboarding({ voiceMode, setVoiceMode }) {
  const navigate = useNavigate();
  
  // âœ… WebSocket ìƒíƒœ
  const [ws, setWs] = useState(null);
  const [isConnected, setIsConnected] = useState(false);
  const [voiceEnabled, setVoiceEnabled] = useState(false);

  
const [isListening, setIsListening] = useState(false);  // ìŒì„± ì¸ì‹ ì¤‘
  const [_isSpeaking, setIsSpeaking] = useState(false);
  const isSpeakingRef = useRef(false);
  const voiceEnabledRef = useRef(false);
  const voiceModeRef = useRef(voiceMode);
  const audioPlayerRef = useRef(null);
  
  const [userDetected, setUserDetected] = useState(false);
  const userDetectedRef = useRef(false);

// í™˜ê²½ ìë™ ê°ì§€
const API_BASE_URL = 'https://54-116-8-71.nip.io';
const ARDUINO_WS_URL = 'ws://10.205.113.235:8080';

  useEffect(() => {
    voiceModeRef.current = voiceMode;
    
    if (!voiceMode) {
      console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ìŒì„± ì¸ì‹ ì¤‘ì§€');
      stopVoiceRecording();
    }
  }, [voiceMode]);

  const handleOrderTypeClick = () => {
    navigate('/main');
  };

  const enableVoice = async () => {
    if (!voiceEnabledRef.current) {
      try {
        console.log('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹œì‘');
        
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ íšë“ ì„±ê³µ');
        stream.getTracks().forEach(track => track.stop());
        
        const utterance = new SpeechSynthesisUtterance('');
        window.speechSynthesis.speak(utterance);
        
        setVoiceEnabled(true);
        voiceEnabledRef.current = true;
        console.log('âœ… ìŒì„± ë° ë§ˆì´í¬ ê¶Œí•œ í™œì„±í™” ì™„ë£Œ');
        
        setTimeout(() => {
          enterFullscreen();
        }, 500);
        
      } catch (error) {
        console.error('âŒ ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜:', error);
        alert('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    }
  };

  const enterFullscreen = () => {
    try {
      const elem = document.documentElement;
      if (elem.requestFullscreen) {
        elem.requestFullscreen();
      } else if (elem.webkitRequestFullscreen) {
        elem.webkitRequestFullscreen();
      } else if (elem.msRequestFullscreen) {
        elem.msRequestFullscreen();
      }
      console.log('ğŸ“º ì „ì²´í™”ë©´ ì „í™˜ ì™„ë£Œ');
    } catch (error) {
      console.error('ì „ì²´í™”ë©´ ì „í™˜ ì˜¤ë¥˜:', error);
    }
  };

  const playWelcomeMessage = () => {
    console.log('=== playWelcomeMessage í˜¸ì¶œë¨ ===');
    
    if (userDetectedRef.current) {
      console.log('[playWelcomeMessage] ì´ë¯¸ ì‚¬ìš©ì ê°ì§€ë¨ - ì¤‘ë³µ ì‹¤í–‰ ì°¨ë‹¨');
      return;
    }
    
    if (isSpeakingRef.current) {
      console.log('[playWelcomeMessage] ìŒì„± ì¬ìƒ ì¤‘, ì¤‘ë³µ ì¬ìƒ ì°¨ë‹¨');
      return;
    }
    
    if (!voiceEnabledRef.current) {
      console.log('[playWelcomeMessage] ìŒì„± ê¶Œí•œ ë¯¸í™œì„±í™” - ì¬ìƒ ë¶ˆê°€');
      return;
    }

    setUserDetected(true);
    userDetectedRef.current = true;
    console.log('âœ… ì‚¬ìš©ì ìµœì´ˆ ê°ì§€ - ì¶”ê°€ ê°ì§€ ë¹„í™œì„±í™”');

    console.log('[playWelcomeMessage] ìŒì„± ì¬ìƒ ì‹œì‘');
    setIsSpeaking(true);
    isSpeakingRef.current = true;

    const audio = new Audio(orderStartAudio);
    audio.volume = 1.0;
    
    audio.onplay = () => {
      console.log('ğŸ”Š "ì£¼ë¬¸ì‹œì‘" ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘');
    };
    
    audio.onended = () => {
      console.log('[audio] "ì£¼ë¬¸ì‹œì‘" ìŒì„± ì¬ìƒ ì¢…ë£Œ');
      
      if (!voiceModeRef.current) {
        console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™”ë¨ - ë°±ì—”ë“œ í˜¸ì¶œ ì¤‘ë‹¨');
        setIsSpeaking(false);
        isSpeakingRef.current = false;
        return;
      }
      
      sendPreRecordedVoiceToBackend();
    };
    
    audio.onerror = (e) => {
      console.error('[audio] ìŒì„± ì¬ìƒ ì˜¤ë¥˜:', e);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      
      if (voiceModeRef.current) {
        startMicRecording();
      }
    };

    audio.play().catch(err => {
      console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', err);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
    });
  };

  const sendPreRecordedVoiceToBackend = async () => {
    try {
      console.log('ğŸ“¤ ë…¹ìŒëœ "ì£¼ë¬¸ì‹œì‘" íŒŒì¼ì„ ë°±ì—”ë“œë¡œ ì „ì†¡ ì¤‘...');
      
      const response = await fetch(orderStartAudio);
      const audioBlob = await response.blob();
      
      let fileToSend = audioBlob;
      
      if (!audioBlob.type || audioBlob.type === '' || !audioBlob.type.includes('audio')) {
        console.warn('âš ï¸ íŒŒì¼ íƒ€ì…ì´ ì—†ê±°ë‚˜ ì˜ëª»ë¨, audio/mpegë¡œ ë³€í™˜');
        fileToSend = new Blob([audioBlob], { type: 'audio/mpeg' });
      }
      
      const file = new File([fileToSend], 'order-start.mp3', { 
        type: 'audio/mpeg',
        lastModified: Date.now()
      });

      const formData = new FormData();
      formData.append('question', file);

      console.log('ğŸ“¤ ë°±ì—”ë“œë¡œ ì „ì†¡ ì¤‘...');
      const backendResponse = await fetch(`${API_BASE_URL}/api/ai/chat-voice`, {
        method: 'POST',
        body: formData,
      });

      if (!backendResponse.ok) {
        throw new Error(`ë°±ì—”ë“œ ì‘ë‹µ ì—ëŸ¬: ${backendResponse.status}`);
      }

      console.log('âœ… ë°±ì—”ë“œ ì‘ë‹µ ìˆ˜ì‹ ');

      const audioPlayer = audioPlayerRef.current;
      
audioPlayer.addEventListener('ended', () => {
  console.log('ğŸ”Š ë°±ì—”ë“œ AI ìŒì„± ì¬ìƒ ì™„ë£Œ');
  setIsSpeaking(false);
  isSpeakingRef.current = false;

  if (voiceModeRef.current) {
    setTimeout(() => {
      startMicRecording();
    }, 2000);  // âœ… 2ì´ˆ ëŒ€ê¸° ì¶”ê°€
  }
}, { once: true });

      await springai.voice.playAudioFormStreamingData(backendResponse, audioPlayer);

    } catch (error) {
      console.error('âŒ ì´ˆê¸° ìŒì„± ì „ì†¡ ì˜¤ë¥˜:', error);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      
      if (voiceModeRef.current) {
        startMicRecording();
      }
    }
  };

const startMicRecording = () => {
  if (!springai || !springai.voice) {
    console.error('âŒ springai.jsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    return;
  }
  
  if (!voiceModeRef.current) {
    console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ë§ˆì´í¬ ì‹œì‘ ì¤‘ë‹¨');
    return;
  }
  
  // âœ… ìŒì„± ì¬ìƒ ì¤‘ì´ë©´ ë§ˆì´í¬ ì‹œì‘ ì•ˆ í•¨
  if (isSpeakingRef.current) {
    console.log('ğŸ”‡ ìŒì„± ì¬ìƒ ì¤‘ - ë§ˆì´í¬ ì‹œì‘ ëŒ€ê¸°');
    return;
  }
  
  console.log('ğŸ¤ ìŒì„± ì¸ì‹ ë§ˆì´í¬ ì‹œì‘');
   setIsListening(true);  // âœ… ì¶”ê°€
  springai.voice.initMic(handleVoice);
  springai.voice.controlSpeakerAnimation('user-speaker', true);
};


  const stopVoiceRecording = () => {
    if (springai && springai.voice) {
      if (springai.voice.mediaRecorder && springai.voice.mediaRecorder.state === 'recording') {
        springai.voice.mediaRecorder.stop();
      }
      if (springai.voice.recognition) {
        springai.voice.recognition.stop();
      }
      springai.voice.controlSpeakerAnimation('user-speaker', false);
      springai.voice.controlSpeakerAnimation('ai-speaker', false);
    }
    window.speechSynthesis.cancel();
  };

  const checkKeywordAndNavigate = (recognizedText) => {
    console.log('ğŸ” í‚¤ì›Œë“œ ì²´í¬:', recognizedText);
    
    const keywords = ['í¬ì¥', 'ë§¤ì¥'];
    
    const foundKeyword = keywords.some(keyword => 
      recognizedText.toLowerCase().includes(keyword.toLowerCase())
    );
    
    if (foundKeyword) {
      console.log('âœ… í‚¤ì›Œë“œ ê°ì§€! Main í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.');
      stopVoiceRecording();
      setTimeout(() => {
        navigate('/main');
      }, 1000);
      return true;
    }
    
    return false;
  };

  const handleVoice = async (mp3Blob) => {
    springai.voice.controlSpeakerAnimation('user-speaker', false);
      setIsListening(false);  // âœ… ì¶”ê°€
    console.log('ğŸ¤ ì‚¬ìš©ì ìŒì„± ìˆ˜ì‹ :', mp3Blob);

    if (!voiceModeRef.current) {
      console.log('ğŸ”‡ ìŒì„± ëª¨ë“œ ë¹„í™œì„±í™” - ìŒì„± ì²˜ë¦¬ ì¤‘ë‹¨');
      return;
    }

    const recognizedText = springai.voice.lastRecognizedText || '';
    console.log('ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:', recognizedText);

    const shouldNavigate = checkKeywordAndNavigate(recognizedText);
    if (shouldNavigate) {
      return;
    }

if (mp3Blob.size < 5000) {
  console.warn('âš ï¸ ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.');
  setTimeout(() => {
    if (voiceModeRef.current) {
      startMicRecording();
    }
  }, 3000);  // âœ… 1000 â†’ 3000 (3ì´ˆ ëŒ€ê¸°)
  return;
}


    setIsSpeaking(true);
    isSpeakingRef.current = true;

    try {
      const formData = new FormData();
      formData.append('question', mp3Blob, 'user-speech.mp3');

      console.log('ğŸ“¤ ë°±ì—”ë“œë¡œ ìŒì„± ì „ì†¡ ì¤‘...');
      const response = await fetch(`${API_BASE_URL}/api/ai/chat-voice`, {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`ë°±ì—”ë“œ ì‘ë‹µ ì—ëŸ¬: ${response.status}`);
      }

      console.log('âœ… ë°±ì—”ë“œ ì‘ë‹µ ìˆ˜ì‹ ');
      
      springai.voice.controlSpeakerAnimation('ai-speaker', true);

      const audioPlayer = audioPlayerRef.current;
      
audioPlayer.addEventListener('ended', () => {
  console.log('ğŸ”Š AI ì‘ë‹µ ìŒì„± ì¬ìƒ ì™„ë£Œ');
  springai.voice.controlSpeakerAnimation('ai-speaker', false);
  setIsSpeaking(false);
  isSpeakingRef.current = false;

  if (voiceModeRef.current) {
    setTimeout(() => {
      startMicRecording();
    }, 2000);  // âœ… 1000 â†’ 2000 (2ì´ˆ ëŒ€ê¸°)
  }
}, { once: true });


      await springai.voice.playAudioFormStreamingData(response, audioPlayer);

    } catch (error) {
      console.error('âŒ ìŒì„± ì²˜ë¦¬ ì¤‘ ì—ëŸ¬:', error);
      setIsSpeaking(false);
      isSpeakingRef.current = false;
      springai.voice.controlSpeakerAnimation('ai-speaker', false);
    }
  };

  // âœ… WebSocketìœ¼ë¡œ ì•„ë‘ì´ë…¸ ì—°ê²°
  const connectArduino = () => {
    try {
      console.log('ğŸ”Œ WebSocket ì—°ê²° ì‹œë„:', ARDUINO_WS_URL);
      
      const socket = new WebSocket(ARDUINO_WS_URL);
      
      socket.onopen = () => {
        console.log('âœ… ì•„ë‘ì´ë…¸ WebSocket ì—°ê²° ì„±ê³µ!');
        setIsConnected(true);
      };
      
      socket.onmessage = (event) => {
        const data = event.data;
        console.log('ğŸ“¡ ì•„ë‘ì´ë…¸ ë°ì´í„°:', data);
        
        // ì—°ê²° í™•ì¸ ë©”ì‹œì§€ ë¬´ì‹œ
        if (data === 'CONNECTED') {
          console.log('âœ… ì„œë²„ ì—°ê²° í™•ì¸');
          return;
        }
        
        if (data.includes('USER_DETECTED')) {
          console.log('ğŸ‰ ì‚¬ìš©ì ê°ì§€!');
          
          if (userDetectedRef.current) {
            console.log('ì´ë¯¸ ê°ì§€ë¨ - ë¬´ì‹œ');
            return;
          }
          
          if (!isSpeakingRef.current && voiceEnabledRef.current) {
            playWelcomeMessage();
          }
        }
      };
      
      socket.onerror = (error) => {
        console.error('âŒ WebSocket ì˜¤ë¥˜:', error);
        alert('ì•„ë‘ì´ë…¸ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\ní™•ì¸ì‚¬í•­:\n1. PCì—ì„œ node server.js ì‹¤í–‰ ì¤‘ì¸ê°€ìš”?\n2. PCì™€ íƒœë¸”ë¦¿ì´ ê°™ì€ Wi-Fiì— ì—°ê²°ë˜ì–´ ìˆë‚˜ìš”?\n3. ARDUINO_WS_URLì˜ IP ì£¼ì†Œê°€ ë§ë‚˜ìš”?');
      };
      
      socket.onclose = () => {
        console.log('âŒ WebSocket ì—°ê²° ì¢…ë£Œ');
        setIsConnected(false);
      };
      
      setWs(socket);
      
    } catch (error) {
      console.error('WebSocket ì—°ê²° ì‹¤íŒ¨:', error);
      alert('WebSocket ì—°ê²° ì‹¤íŒ¨:\n' + error.message);
    }
  };

  const disconnectArduino = () => {
    if (ws) {
      ws.close();
      setWs(null);
      setIsConnected(false);
      console.log('âœ… ì•„ë‘ì´ë…¸ ì—°ê²° í•´ì œ');
    }
  };

  useEffect(() => {
    return () => {
      stopVoiceRecording();
      if (ws) {
        ws.close();
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  return (
    <div className="mmaaiinn">
          {isListening && (
      <div className="voice-listening-overlay">
        <div className="voice-listening-content">
          <div className="microphone-icon">ğŸ¤</div>
          <p className="listening-text">ë“£ê³  ìˆìŠµë‹ˆë‹¤...</p>
          <div className="sound-wave">
            <span></span>
            <span></span>
            <span></span>
            <span></span>
            <span></span>
          </div>
        </div>
      </div>
    )}
      {!voiceEnabled && (
        <div style={{
          position: 'fixed',
          top: '50%',
          left: '50%',
          transform: 'translate(-50%, -50%)',
          zIndex: 9999,
          background: 'white',
          padding: '40px',
          borderRadius: '20px',
          boxShadow: '0 10px 50px rgba(0,0,0,0.3)',
          textAlign: 'center'
        }}>
          <h2 style={{marginBottom: '20px', fontSize: '28px'}}>ğŸ”Š ìŒì„± ì•ˆë‚´ ì‹œì‘</h2>
          <p style={{marginBottom: '30px', fontSize: '18px', color: '#666'}}>
            ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
          </p>
          <button 
            className="voice-activation-btn"
            onClick={enableVoice}
            style={{
              background: '#4CAF50',
              color: 'white',
              padding: '20px 40px',
              fontSize: '24px',
              border: 'none',
              borderRadius: '10px',
              cursor: 'pointer',
              boxShadow: '0 4px 10px rgba(0,0,0,0.2)'
            }}
          >
            ìŒì„± í™œì„±í™”
          </button>
        </div>
      )}

      <div className="arduino-status">
        {isConnected ? (
          <div className="status-connected">
            <span className="status-dot"></span>
            ì•„ë‘ì´ë…¸ ì—°ê²°ë¨ (WebSocket)
            {userDetected && (
              <span style={{marginLeft: '10px', color: '#4CAF50', fontSize: '14px'}}>
                âœ“ ì‚¬ìš©ì ê°ì§€ë¨
              </span>
            )}
            {!voiceMode && (
              <span style={{marginLeft: '10px', color: '#FF9800', fontSize: '14px'}}>
                ğŸ–ï¸ í„°ì¹˜ ëª¨ë“œ
              </span>
            )}
            <button className="disconnect-btn arduino-btn" onClick={disconnectArduino} style={{marginLeft: '10px'}}>
              ğŸ”Œ ì—°ê²° í•´ì œ
            </button>
          </div>
        ) : (
          <button className="connect-btn arduino-btn" onClick={connectArduino}>
            ğŸ”Œ ì•„ë‘ì´ë…¸ ì—°ê²° (WebSocket)
          </button>
        )}
      </div>

      <audio ref={audioPlayerRef} style={{ display: 'none' }} />

      <div style={{ display: 'none' }}>
        <div id="user-speaker"></div>
        <div id="ai-speaker"></div>
      </div>

      <section className="onboard-total-ct">
        <div className="logo-ct">
          <div className="eulji-logo"> <img src={eulji} alt="eulji logo" /> </div>
          <div className="middle-line"><p> </p></div>
          <div className="kiosk-logo"> <img src={drinklogo} alt="drink logo" /> </div>
        </div>

        <div className="kiosk-title">EU AI ìŒì„± í‚¤ì˜¤ìŠ¤í¬ </div>
        <p className="kiosk-eng"> Ai Voice Kiosk </p>
        <p className="click"> í´ë¦­í•˜ì—¬ ì£¼ë¬¸í•˜ì„¸ìš”. </p>
        <p className="kiosk-solution"> ì£¼ë¬¸ ë°©ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”</p>

        <div className="order-method-ct">
          <section className="Take-out-ct" onClick={handleOrderTypeClick}>
            <div className="tt">
              <div className="takeout-img">ğŸ›ï¸</div>
            </div>
            <p className="takeout"> í¬ì¥ </p>
            <p className="takeout-sub"> Take out</p>
          </section>

          <section className="Dine-in-ct" onClick={handleOrderTypeClick}>
            <div className="tt2">
              <div className="dinein-img">ğŸª‘</div>
            </div>
            <p className="pack"> ë§¤ì¥ </p>
            <p className="pack-sub"> Dine in</p>
          </section>
        </div>
      </section>
    </div>
  );
}

export default Onboarding;
